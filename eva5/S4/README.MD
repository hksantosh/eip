# MNIST Classification using less than 20k parameters and without using FC layers
* In this model, 2d batch normalization and 1D dropouts have been applied for each layer except the final layer
* First block starts with a convolution layer that is made of 10 3x3 convolution filters. The convolution layer accepts images in batches of 64 and generates 10 channels and maintains the input size 28x28 (using padding during convlution). This layer is followed by 2x2 maxpooling which reduces the dimensions of the 10 channels to 14x14. The receptive field of this block is 6x6.
* Second block consists of two layers each containing 16 3x3 convolution filters. These convolution layers increase the depth of feature maps to 16. These convolution layers are followed by 2x2 maxpooling which reduces the dimensions of feature maps to 7x7. Receptive field size has now increased to 20.
* Third block consists of a single layer containing 20 3x3 convolution filters. These convolution layers increase the depth of feature maps to 20. Receptive field size has now increased to 22 which means the input image is still not entirely visible to the model from this layer.
* Second block consists of two layers each containing 16 3x3 convolution filters. These convolution layers increase the depth of feature maps to 16. These convolution layers are followed by 2x2 maxpooling which reduces the dimensions of feature maps to 7x7. Receptive field size has now increased to 20.
